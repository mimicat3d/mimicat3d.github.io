<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer">
  <meta name="keywords" content="3D Pose Transfer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title"><b>&#128568; MimiCAT</b>: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Preprint, 2025</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zenghaochai.com">Zenghao Chai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.chentang.cc/#">Chen Tang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/yongkangwong">Yongkang Wong</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://dawdleryang.github.io">Xulei Yang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~mohan/">Mohan Kankanhalli</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>School of Computing, National University of Singapore,</span><br>
            <span class="author-block"><sup>2</sup>MMLab, The Chinese University of Hong Kong,</span>
            <span class="author-block"><sup>3</sup>Institute for Infocomm Research, A<sup>*</sup>STAR</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.18370"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.18370"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (TBD)</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/czh-98/MimiCAT.git"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Data (TBD)</span>
                  </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<hr class="divider" />

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Pipeline. -->
      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3" style="text-align: justify;">Overview</h2>
          <p>
            <strong>Overview of MimiCAT for category-free pose transfer.</strong>
          </p>
          <p>
            MimiCAT takes a paired source pose and target character as input. It first employs the correspondence transformer <span>\( \mathcal{G} \)</span> to estimate soft keypoint correspondences, then refines the initialized transformations using the pose transfer transformer <span>\( \mathcal{H} \)</span> to generate the target transformations. Finally, the target character is deformed into the desired pose through linear blend skinning (LBS).
          </p>
          <img id="pipeline" src="./static/images/pipeline.jpg" style="width:1000px; margin-top:10px;margin-bottom:-20px;"/>

        </div>
      </div>
      <!--/ Visual Effects. -->

      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3" style="text-align: justify;">&nbsp;</h2>
          <p>
            <strong>MimiCAT for category-free 3D pose transfer.</strong>
          </p>
          <p>
              Given source character with desired poses (<i>left</i>), our model faithfully transfers the given pose to the target characters (<i>right</i>) across completely different categories, proportions and topologies, without requirement of manually labeled correspondence.
          </p>
          <img id="pipeline" src="./static/images/teaser.jpg" style="width:1000px; margin-top:10px;margin-bottom:-20px;"/>
        </div>
      </div>



    </div>
  </div>
</section>

<hr class="divider" />



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D pose transfer aims to transfer the pose-style of a source mesh to a target character while preserving both the target's geometry and the source's pose characteristic. Existing methods are largely restricted to characters with similar structures and fail to generalize to category-free settings (e.g., transferring a humanoid's pose to a quadruped). The key challenge lies in the structural and transformation diversity inherent in distinct character types, which often leads to mismatched regions and poor transfer quality. 
          </p>
          <p>
            To address these issues, we first construct a million-scale pose dataset across hundreds of distinct characters. We further propose <strong>MimiCAT</strong>, a cascade-transformer model designed for category-free 3D pose transfer. Instead of relying on strict one-to-one correspondence mappings, MimiCAT leverages semantic keypoint labels to learn a novel soft correspondence that enables flexible many-to-many matching across characters. The pose transfer is then formulated as a conditional generation process, in which the source transformations are first projected onto the target through soft correspondence matching and subsequently refined using shape-conditioned representations. 
          </p>
          <p>
            Extensive qualitative and quantitative experiments demonstrate that MimiCAT transfers plausible poses across different characters, significantly outperforming prior methods that are limited to narrow category transfer (e.g., humanoid-to-humanoid).
            </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <hr class="divider" />

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <!-- <div class="publication-video">
          <iframe src="https://www.youtube.com"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div> -->
        <p>TBD</p>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<hr class="divider" />


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <!-- Pipeline. -->
      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3" style="text-align: justify;">Pipeline</h2>
          <p>
            <strong>Overview of the correspondence transformer <span>\( \mathcal{G} \)</span>.</strong>
            We (a) first extract shape and keypoint tokens using the shape projector and keypoint encoder, (b) fuse shape conditions with respective keypoint latents through transformer blocks, (c) estimate correspondences via learnable affinity weights followed by the Sinkhorn algorithm, and (d) produce soft-matching correspondences between the given characters.
          </p>
          <img id="pipeline" src="./static/images/fig_g.jpg" style="width:1000px; margin-top:10px;margin-bottom:-20px;"/>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <div class="column">
        <div class="content has-text-justified">
          <h2 class="title is-3" style="text-align: justify;">&nbsp;</h2>
          <p>
            <strong>Overview of the correspondence transformer <span>\( \mathcal{H} \)</span>.</strong>
              We (a) first perform cross-attention to extract deformation-aware cues for shape tokenization and apply correspondence-aware initialization for keypoint tokenization. (b) The shape and keypoint tokens are fed into transformer blocks to derive high-level representations, and decode into refined target transformations. (c) the posed target mesh is generated by deforming the canonical target through Eq. 1.
          </p>
          <img id="pipeline" src="./static/images/fig_h.jpg" style="width:1000px; margin-top:10px;margin-bottom:-20px;"/>
        </div>
      </div>


      </div>
  </div>
</section>
<hr class="divider" />



<section class="section">
  <div class="container is-max-desktop">
    <!-- Dataset. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset: PokeAnimDB</h2>

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3> -->
        <div class="content has-text-justified">
          <p>
            We collect a dataset comprises hundreds of characters spanning a broad spectrum of species and morphologies, including humanoids, quadrupeds, birds, reptiles, fishes, and insects. Each character is paired with artist-designed skeletal animations, resulting in a total of 28k motions and 4.4 million frames.
          </p>
          <img id="pipeline" src="./static/images/fig_dataset.jpg" style="width:1000px; margin-top:10px;margin-bottom:-20px;"/>

        </div>
        <br/>
        <!--/ Interpolating. -->

      </div>
    </div>
    <!--/ Animation. -->



  </div>
</section>

<hr class="divider" />

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title has-text-centered">BibTeX</h2>
    <pre><code>@article{chai2025mimicat,
  author    = {Chai, Zenghao and Tang, Chen and Wong, Yongkang and Yang, Xulei and Kankanhalli, Mohan},
  title     = {MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer},
  journal   = {arXiv preprint arXiv:2511.18370},
  year      = {2025},
}</code></pre>
  </div>
</section>

<hr class="divider" />

<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website template was adapted from <a href="https://nerfies.github.io/">Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
